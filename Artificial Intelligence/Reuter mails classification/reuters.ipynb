{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41rIEpjvuq8g",
        "outputId": "aa7aaa8b-ac82-46b4-d990-1d6092ff953d"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_excel('reuters.xlsx')\n",
        "X, y = data.text, data.topic\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lem_texts = []\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "for t in X:\n",
        "    lem = [wnl.lemmatize(word) for word in str(t).split()]\n",
        "    lem_texts.append(' '.join(lem))\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2000, min_df=10, max_df=0.8,\n",
        "                     stop_words=nltk.corpus.stopwords.words('english'))\n",
        "#max_features - к-сть слів, які використовуються для класифікації\n",
        "#min_df - мін к-сть текстів, у яких міститься слово\n",
        "#max_df - макс відсоток файлів, у яких міститься слово\n",
        "#stop_words - шумові слова\n",
        "X = cv.fit_transform(lem_texts).toarray()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer()\n",
        "X = tfidfconverter.fit_transform(X).toarray()\n",
        "\n",
        "print(f'Topics: {len(set(y))}, X_shape: {X.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Topics: 82, X_shape: (10717, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oxEBdy_wWmq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLyGDXYAyI4-",
        "outputId": "d16264ff-0cab-430f-8785-3d24788df77d"
      },
      "source": [
        "import sklearn.naive_bayes\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                             accuracy_score)\n",
        "\n",
        "models = [\n",
        "          sklearn.naive_bayes.CategoricalNB(),\n",
        "          sklearn.naive_bayes.BernoulliNB(),\n",
        "          sklearn.naive_bayes.ComplementNB(),\n",
        "          sklearn.naive_bayes.GaussianNB(),\n",
        "          sklearn.naive_bayes.MultinomialNB(),\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'\\nModel: \\t{model}')\n",
        "    #print(confusion_matrix(y_test,y_pred))\n",
        "    #print(classification_report(y_test,y_pred))\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \tCategoricalNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "0.37406716417910446\n",
            "\n",
            "Model: \tBernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "0.7416044776119403\n",
            "\n",
            "Model: \tComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
            "0.8190298507462687\n",
            "\n",
            "Model: \tGaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.6427238805970149\n",
            "\n",
            "Model: \tMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "0.7779850746268657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_abVbpryJzY",
        "outputId": "21775ec8-7a07-4506-bf02-6cae486719e5"
      },
      "source": [
        "import sklearn.linear_model\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                             accuracy_score)\n",
        "\n",
        "models = [\n",
        "          sklearn.linear_model.LogisticRegression(),\n",
        "          sklearn.linear_model.PassiveAggressiveClassifier(),\n",
        "          sklearn.linear_model.Perceptron(),\n",
        "          sklearn.linear_model.RidgeClassifier(),\n",
        "          sklearn.linear_model.SGDClassifier(),\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'\\nModel: \\t{model}')\n",
        "    #print(confusion_matrix(y_test,y_pred))\n",
        "    #print(classification_report(y_test,y_pred))\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \tLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "0.8586753731343284\n",
            "\n",
            "Model: \tPassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
            "                            early_stopping=False, fit_intercept=True,\n",
            "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
            "                            n_jobs=None, random_state=None, shuffle=True,\n",
            "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "                            warm_start=False)\n",
            "0.8638059701492538\n",
            "\n",
            "Model: \tPerceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
            "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
            "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
            "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "0.8521455223880597\n",
            "\n",
            "Model: \tRidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "                max_iter=None, normalize=False, random_state=None,\n",
            "                solver='auto', tol=0.001)\n",
            "0.8759328358208955\n",
            "\n",
            "Model: \tSGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
            "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "0.8871268656716418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4igZIWrlyJ4v",
        "outputId": "2388cc0c-9e3f-4621-ae09-2b8949d41a8a"
      },
      "source": [
        "import sklearn.svm\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                             accuracy_score)\n",
        "\n",
        "models = [\n",
        "          sklearn.svm.LinearSVC(),\n",
        "          sklearn.svm.SVC(),\n",
        "          sklearn.svm.OneClassSVM(),\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'\\nModel: \\t{model}')\n",
        "    #print(confusion_matrix(y_test,y_pred))\n",
        "    #print(classification_report(y_test,y_pred))\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \tLinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n",
            "0.8857276119402985\n",
            "\n",
            "Model: \tSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "0.8642723880597015\n",
            "\n",
            "Model: \tOneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='scale', kernel='rbf',\n",
            "            max_iter=-1, nu=0.5, shrinking=True, tol=0.001, verbose=False)\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6ypd19ayJ7Z",
        "outputId": "5551fbee-dd82-4342-dd4e-2bb9912b1300"
      },
      "source": [
        "import sklearn.multiclass\n",
        "import sklearn.multioutput\n",
        "import sklearn.neighbors\n",
        "import sklearn.neural_network\n",
        "import sklearn.semi_supervised\n",
        "import sklearn.tree\n",
        "import sklearn.dummy\n",
        "import sklearn.ensemble\n",
        "\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                             accuracy_score)\n",
        "\n",
        "models = [\n",
        "          #sklearn.multiclass.OneVsRestClassifier(),\n",
        "          #sklearn.multiclass.OneVsOneClassifier(),\n",
        "          #sklearn.multiclass.OutputCodeClassifier(),\n",
        "          #sklearn.multioutput.ClassifierChain(),\n",
        "          #sklearn.multioutput.MultiOutputClassifier(),\n",
        "          sklearn.neighbors.KNeighborsClassifier(),\n",
        "          #sklearn.neighbors.RadiusNeighborsClassifier(),\n",
        "          sklearn.neighbors.NearestCentroid(),\n",
        "          sklearn.neural_network.MLPClassifier(),\n",
        "          sklearn.tree.DecisionTreeClassifier(),\n",
        "          sklearn.tree.ExtraTreeClassifier(),\n",
        "          sklearn.dummy.DummyClassifier(),\n",
        "          sklearn.ensemble.AdaBoostClassifier(),\n",
        "          sklearn.ensemble.BaggingClassifier(),\n",
        "          sklearn.ensemble.ExtraTreesClassifier(),\n",
        "          sklearn.ensemble.GradientBoostingClassifier(),\n",
        "          sklearn.ensemble.RandomForestClassifier(),\n",
        "          #sklearn.ensemble.StackingClassifier(),\n",
        "          #sklearn.ensemble.VotingClassifier(),\n",
        "          #sklearn.ensemble.HistGradientBoostingClassifier(),\n",
        "          #sklearn.semi_supervised.SelfTrainingClassifier(),\n",
        "          sklearn.semi_supervised.LabelPropagation(),\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'\\nModel: \\t{model}')\n",
        "    #print(confusion_matrix(y_test,y_pred))\n",
        "    #print(classification_report(y_test,y_pred))\n",
        "    print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \tKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "0.8339552238805971\n",
            "\n",
            "Model: \tNearestCentroid(metric='euclidean', shrink_threshold=None)\n",
            "0.7467350746268657\n",
            "\n",
            "Model: \tMLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n",
            "0.8703358208955224\n",
            "\n",
            "Model: \tDecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "0.7686567164179104\n",
            "\n",
            "Model: \tExtraTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                    min_samples_leaf=1, min_samples_split=2,\n",
            "                    min_weight_fraction_leaf=0.0, random_state=None,\n",
            "                    splitter='random')\n",
            "0.6851679104477612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model: \tDummyClassifier(constant=None, random_state=None, strategy='warn')\n",
            "0.18703358208955223\n",
            "\n",
            "Model: \tAdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "0.4766791044776119\n",
            "\n",
            "Model: \tBaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
            "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
            "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
            "                  warm_start=False)\n",
            "0.8283582089552238\n",
            "\n",
            "Model: \tExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                     criterion='gini', max_depth=None, max_features='auto',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                     min_samples_leaf=1, min_samples_split=2,\n",
            "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
            "                     warm_start=False)\n",
            "0.84375\n",
            "\n",
            "Model: \tGradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "0.8143656716417911\n",
            "\n",
            "Model: \tRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "0.8442164179104478\n",
            "\n",
            "Model: \tLabelPropagation(gamma=20, kernel='rbf', max_iter=1000, n_jobs=None,\n",
            "                 n_neighbors=7, tol=0.001)\n",
            "0.8288246268656716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBgO6z20yJ9i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoOD0mXeyKAf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}